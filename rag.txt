RAG_Ollama

conda create -n rag python=3.10 -y
conda activate rag

cd rag_pipeline
pip install -r requirements.txt

cd agent_tools
pip install -r requirements.txt




this will run a container called ollama and pull use image called ollama. 0v is the volume mount, where it stores the llama3 model in next step:
docker run -d --name ollama -p 11434:11434 -v ollama:/root/.ollama --restart unless-stopped ollama/ollama



This downloads llama3 inside ollama container running in docker
curl http://localhost:11434/api/pull -d '{"name": "llama3"}'

#chekc what is inside:
docker exec -it d541e8bd5a71 /bin/sh
cd root/.ollama

#in both of the folders
python3 main.py


##########
#build rag_docker image 
#########

docker build -t yogender027/rag-agent:v3 .
docker push yogender027/rag-agent:v3

###############
#copy inside a kind cluster from local machine
#############
docker cp /home/yogender/Desktop/kind/ollma/rag_ollama/rag_infra/local_model kubeflow-control-plane:/local_model
Successfully copied 439MB to kubeflow-control-plane:/local_model


#############
#copy inside pvc in a pod from notebook into kind into pod
#############
kubectl cp /home/yogender/Desktop/kind/ollma/rag_vllm/text.txt ollama/rag-agent-69fb5b5cb5-mxtnx:/data/text.txt

rag-agent-69fb5b5cb5-mxtnx 




#####################################
#build deployment without docker push
#####################################
#Load dokcer image inside of kind
docker images -a
kind load docker-image yogender027/ollama-n8n-rag:1.0.0 --name kubeflow

#remove images from kind:
docker exec -it kubeflow-control-plane crictl images
docker exec -it kubeflow-control-plane crictl rmi 9745ee7c3802f

#or remove without knowing the image id just by name - easy	
docker exec -it kubeflow-control-plane crictl rmi yogender027/ollama-n8n-rag:1.0.0